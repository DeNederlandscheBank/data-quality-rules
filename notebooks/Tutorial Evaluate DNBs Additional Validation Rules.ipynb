{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Evaluate DNBs additional Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a tutorial for the evaluation of DNBs additional Rules for the following Solvency II reports:\n",
    "- Annual Reporting Solo (ARS); and\n",
    "- Quarterly Reporting Solo (QRS)\n",
    "\n",
    "Besides the necessary preparation, the tutorial consists of 6 steps:\n",
    "1. Read possible datapoints\n",
    "2. Read data\n",
    "3. Clean data\n",
    "4. Read additional rules\n",
    "5. Evaluate rules\n",
    "6. Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # dataframes\n",
    "import numpy as np  # mathematical functions, arrays and matrices\n",
    "from os.path import join, isfile  # some os dependent functionality\n",
    "import data_patterns  # evaluation of patterns\n",
    "import regex as re  # regular expressions\n",
    "from pprint import pprint  # pretty print\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRYPOINT: 'ARS' for 'Annual Reporting Solo' or 'QRS' for 'Quarterly Reporting Solo'\n",
    "# INSTANCE: Name of the report you want to evaluate the additional rules for\n",
    "\n",
    "ENTRYPOINT = 'ARS'  \n",
    "INSTANCE = 'ars_240_instance'  # Test instances: ars_240_instance or qrs_240_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAPOINTS_PATH: path to the excel-file containing all possible datapoints (simplified taxonomy)\n",
    "# RULES_PATH: path to the excel-file with the additional rules\n",
    "# INSTANCES_DATA_PATH: path to the source data\n",
    "# RESULTS_PATH: path to the results\n",
    "\n",
    "DATAPOINTS_PATH = join('..', 'data', 'datapoints')\n",
    "RULES_PATH = join('..', 'solvency2-rules')\n",
    "INSTANCES_DATA_PATH = join('..', 'data', 'instances', INSTANCE)\n",
    "RESULTS_PATH = join('..', 'results') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We log to rules.log in the data/instances path\n",
    "\n",
    "logging.basicConfig(filename = join(INSTANCES_DATA_PATH, 'rules.log'),level = logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read possible datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data/datapoints directory there is a file for both ARS and QRS in which all possible datapoints are listed (simplified taxonomy).  \n",
    "We will use this information to add all unreported datapoints to the imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabelcode</th>\n",
       "      <th>datapunt</th>\n",
       "      <th>rij</th>\n",
       "      <th>kolom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S.01.01.01.01</td>\n",
       "      <td>R0010C0010</td>\n",
       "      <td>R0010</td>\n",
       "      <td>C0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S.01.01.01.01</td>\n",
       "      <td>R0020C0010</td>\n",
       "      <td>R0020</td>\n",
       "      <td>C0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S.01.01.01.01</td>\n",
       "      <td>R0030C0010</td>\n",
       "      <td>R0030</td>\n",
       "      <td>C0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S.01.01.01.01</td>\n",
       "      <td>R0040C0010</td>\n",
       "      <td>R0040</td>\n",
       "      <td>C0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.01.01.01.01</td>\n",
       "      <td>R0060C0010</td>\n",
       "      <td>R0060</td>\n",
       "      <td>C0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tabelcode    datapunt    rij  kolom\n",
       "0  S.01.01.01.01  R0010C0010  R0010  C0010\n",
       "1  S.01.01.01.01  R0020C0010  R0020  C0010\n",
       "2  S.01.01.01.01  R0030C0010  R0030  C0010\n",
       "3  S.01.01.01.01  R0040C0010  R0040  C0010\n",
       "4  S.01.01.01.01  R0060C0010  R0060  C0010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datapoints = pd.read_csv(join(DATAPOINTS_PATH, ENTRYPOINT.upper() + '.csv'), sep=\";\").fillna(\"\")  # load file to dataframe\n",
    "df_datapoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish 2 types of tables: \n",
    "- With a closed-axis, e.g. the balance sheet: an entity reports only 1 balance sheet per period\n",
    "- With an open-axis, e.g. the list of assets: an entity reports several 'rows of data' in the relevant table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we gather some general information:\n",
    "- A list of all possible reported tables\n",
    "- A list of all reported tables\n",
    "- A list of all tables that have not been reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_complete_set = df_datapoints.tabelcode.sort_values().unique().tolist()\n",
    "tables_reported = [table for table in tables_complete_set if isfile(join(INSTANCES_DATA_PATH, table + '.pickle'))]\n",
    "tables_not_reported = [table for table in tables_complete_set if table not in tables_reported]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides all separate tables, the 'Tutorial Convert XBRL-instance to CSV, HTML and pickles' also outputs a large dataframe with the data from all closed-axis tables combined.  \n",
    "We use this dataframe for evaluating the patterns on closed-axis tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>S.01.01.01.01,R0010,C0010</th>\n",
       "      <th>S.01.01.01.01,R0020,C0010</th>\n",
       "      <th>S.01.01.01.01,R0030,C0010</th>\n",
       "      <th>S.01.01.01.01,R0040,C0010</th>\n",
       "      <th>S.01.01.01.01,R0060,C0010</th>\n",
       "      <th>S.01.01.01.01,R0070,C0010</th>\n",
       "      <th>S.01.01.01.01,R0080,C0010</th>\n",
       "      <th>S.01.01.01.01,R0090,C0010</th>\n",
       "      <th>S.01.01.01.01,R0100,C0010</th>\n",
       "      <th>S.01.01.01.01,R0110,C0010</th>\n",
       "      <th>...</th>\n",
       "      <th>S.29.03.01.06,R0330,C0100</th>\n",
       "      <th>S.29.03.01.06,R0330,C0110</th>\n",
       "      <th>S.29.03.01.06,R0340,C0100</th>\n",
       "      <th>S.29.03.01.06,R0340,C0110</th>\n",
       "      <th>S.29.03.01.06,R0350,C0100</th>\n",
       "      <th>S.29.03.01.06,R0350,C0110</th>\n",
       "      <th>S.29.03.01.07,R0360,C0120</th>\n",
       "      <th>S.29.03.01.07,R0360,C0130</th>\n",
       "      <th>S.29.03.01.07,R0370,C0120</th>\n",
       "      <th>S.29.03.01.07,R0370,C0130</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0LFF1WMNTWG5PTIYYI38</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>Reported</td>\n",
       "      <td>Not reported other reason</td>\n",
       "      <td>Exempted under Article 35 (6) to (8)</td>\n",
       "      <td>Reported</td>\n",
       "      <td>Not reported as no off-balance sheet items</td>\n",
       "      <td>Not reported as no unlimited guarantees received</td>\n",
       "      <td>Reported</td>\n",
       "      <td>Not reported as no activity outside the home c...</td>\n",
       "      <td>Not reported as no direct insurance business</td>\n",
       "      <td>Not reported other reason</td>\n",
       "      <td>...</td>\n",
       "      <td>5.852015e+08</td>\n",
       "      <td>7.837748e+08</td>\n",
       "      <td>7.128474e+08</td>\n",
       "      <td>65836985.03</td>\n",
       "      <td>9.328439e+08</td>\n",
       "      <td>5.850669e+08</td>\n",
       "      <td>56406511.08</td>\n",
       "      <td>8.012159e+08</td>\n",
       "      <td>8.769882e+08</td>\n",
       "      <td>6.403964e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 6574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                S.01.01.01.01,R0010,C0010  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31                  Reported   \n",
       "\n",
       "                                 S.01.01.01.01,R0020,C0010  \\\n",
       "entity               period                                  \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported other reason   \n",
       "\n",
       "                                            S.01.01.01.01,R0030,C0010  \\\n",
       "entity               period                                             \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Exempted under Article 35 (6) to (8)   \n",
       "\n",
       "                                S.01.01.01.01,R0040,C0010  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31                  Reported   \n",
       "\n",
       "                                                  S.01.01.01.01,R0060,C0010  \\\n",
       "entity               period                                                   \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported as no off-balance sheet items   \n",
       "\n",
       "                                                        S.01.01.01.01,R0070,C0010  \\\n",
       "entity               period                                                         \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported as no unlimited guarantees received   \n",
       "\n",
       "                                S.01.01.01.01,R0080,C0010  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31                  Reported   \n",
       "\n",
       "                                                         S.01.01.01.01,R0090,C0010  \\\n",
       "entity               period                                                          \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported as no activity outside the home c...   \n",
       "\n",
       "                                                    S.01.01.01.01,R0100,C0010  \\\n",
       "entity               period                                                     \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported as no direct insurance business   \n",
       "\n",
       "                                 S.01.01.01.01,R0110,C0010  ...  \\\n",
       "entity               period                                 ...   \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  Not reported other reason  ...   \n",
       "\n",
       "                                S.29.03.01.06,R0330,C0100  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              5.852015e+08   \n",
       "\n",
       "                                S.29.03.01.06,R0330,C0110  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              7.837748e+08   \n",
       "\n",
       "                                S.29.03.01.06,R0340,C0100  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              7.128474e+08   \n",
       "\n",
       "                                S.29.03.01.06,R0340,C0110  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31               65836985.03   \n",
       "\n",
       "                                S.29.03.01.06,R0350,C0100  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              9.328439e+08   \n",
       "\n",
       "                                S.29.03.01.06,R0350,C0110  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              5.850669e+08   \n",
       "\n",
       "                                S.29.03.01.07,R0360,C0120  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31               56406511.08   \n",
       "\n",
       "                                S.29.03.01.07,R0360,C0130  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              8.012159e+08   \n",
       "\n",
       "                                S.29.03.01.07,R0370,C0120  \\\n",
       "entity               period                                 \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              8.769882e+08   \n",
       "\n",
       "                                S.29.03.01.07,R0370,C0130  \n",
       "entity               period                                \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31              6.403964e+08  \n",
       "\n",
       "[1 rows x 6574 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_closed_axis = pd.read_pickle(join(INSTANCES_DATA_PATH, INSTANCE + '.pickle'))\n",
    "tables_closed_axis = sorted(list(set(x[:13] for x in df_closed_axis.columns)))\n",
    "df_closed_axis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For open-axis tables we create a dictionary with all data per table.  \n",
    "Later we will evaluate the additional rules on each seperate table in this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-axis tables:\n",
      "['S.01.03.01.01', 'S.01.03.01.02', 'S.03.02.01.01', 'S.03.03.01.01', 'S.06.02.01.01', 'S.06.02.01.02', 'S.06.03.01.01', 'S.07.01.01.01', 'S.08.01.01.01', 'S.08.01.01.02', 'S.08.02.01.01', 'S.08.02.01.02', 'S.09.01.01.01', 'S.10.01.01.01', 'S.11.01.01.01', 'S.11.01.01.02', 'S.14.01.01.01', 'S.14.01.01.02', 'S.14.01.01.03', 'S.14.01.01.04', 'S.15.01.01.01', 'S.15.02.01.01', 'S.21.02.01.01', 'S.23.04.01.01', 'S.23.04.01.02', 'S.23.04.01.03', 'S.23.04.01.04', 'S.23.04.01.05', 'S.23.04.01.06', 'S.23.04.01.07', 'S.24.01.01.01', 'S.24.01.01.02', 'S.24.01.01.05', 'S.24.01.01.06', 'S.24.01.01.07', 'S.24.01.01.08', 'S.24.01.01.09', 'S.25.02.01.01', 'S.25.03.01.01', 'S.30.02.01.03', 'S.30.02.01.04', 'S.30.03.01.01', 'S.30.04.01.01', 'S.30.04.01.02', 'S.30.04.01.03', 'S.31.01.01.01', 'S.31.01.01.02', 'S.31.02.01.01', 'S.31.02.01.02', 'S.36.01.01.01', 'S.36.02.01.01', 'S.36.03.01.01', 'S.36.04.01.01']\n"
     ]
    }
   ],
   "source": [
    "dict_open_axis = {}\n",
    "tables_open_axis = [table for table in tables_reported if table not in tables_closed_axis]\n",
    "\n",
    "for table in tables_open_axis:\n",
    "    df = pd.read_pickle(join(INSTANCES_DATA_PATH, table + '.pickle'))\n",
    "    \n",
    "    # Identify which columns within the open-axis table make a table row unique (index-columns):\n",
    "    index_columns_open_axis = [col for col in list(df.index.names) if col not in ['entity','period']]\n",
    "    \n",
    "    # Duplicate index-columns to data columns:\n",
    "    df.reset_index(level=index_columns_open_axis, inplace=True)\n",
    "    for i in range(len(index_columns_open_axis)):\n",
    "        df['index_col_' + str(i)] = df[index_columns_open_axis[i]].astype(str)\n",
    "        df.set_index(['index_col_' + str(i)], append=True, inplace=True)\n",
    "        \n",
    "    dict_open_axis[table] = df \n",
    "\n",
    "print(\"Open-axis tables:\")\n",
    "print(list(dict_open_axis.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make 2 modifications on the data:\n",
    "1. Add unreported datapoints  \n",
    "so rules (partly) pointing to unreported datapoints can still be evaluated\n",
    "2. Change string values to uppercase  \n",
    "because the additional rules are defined using capital letters for textual comparisons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datapoints = [x.replace(',,',',') for x in \n",
    "                  list(df_datapoints['tabelcode'] + ',' + df_datapoints['rij'] + ',' + df_datapoints['kolom'])]\n",
    "all_datapoints_closed = [x for x in all_datapoints if x[:13] in tables_closed_axis]\n",
    "all_datapoints_open = [x for x in all_datapoints if x[:13] in tables_open_axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-axis tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add not reported datapoints to the dataframe with data from closed axis tables:\n",
    "for col in [column for column in all_datapoints_closed if column not in list(df_closed_axis.columns)]:\n",
    "    df_closed_axis[col] = np.nan\n",
    "df_closed_axis.fillna(0, inplace = True)\n",
    "\n",
    "# string values to uppercase\n",
    "df_closed_axis = df_closed_axis.applymap(lambda s:s.upper() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-axis tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in [table for table in dict_open_axis.keys()]:\n",
    "    all_datapoints_table = [x for x in all_datapoints_open if x[:13] == table]\n",
    "    for col in [column for column in all_datapoints_table if column not in list(dict_open_axis[table].columns)]:\n",
    "        dict_open_axis[table][col] = np.nan\n",
    "    dict_open_axis[table].fillna(0, inplace = True)\n",
    "    \n",
    "    dict_open_axis[table] = dict_open_axis[table].applymap(lambda s:s.upper() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read additional rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNBs additional validation rules are published as an Excel file on the DNB statistics website.  \n",
    "We included the Excel file in the project under data/downloaded files.\n",
    "\n",
    "The rules are already converted to a syntax Python can interpret, using the notebook: 'Convert DNBs Additional Validation Rules to Patterns'.  \n",
    "In the next line of code we read these converted rules (patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patterns = pd.read_excel(join(RULES_PATH, ENTRYPOINT.lower() + '_patterns_additional_rules.xlsx'), engine='openpyxl').fillna(\"\").set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-axis tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to evaluate the rules for closed-axis tables, we need to filter out:\n",
    "- patterns for open-axis tables; and\n",
    "- patterns pointing to tables that are not reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>support</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>confidence</th>\n",
       "      <th>pattern status</th>\n",
       "      <th>encodings</th>\n",
       "      <th>pandas co</th>\n",
       "      <th>pandas ex</th>\n",
       "      <th>xbrl co</th>\n",
       "      <th>xbrl ex</th>\n",
       "      <th>Error message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S.01.01_111</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.01.01.01,R0580,C0010']=='REPORTED...</td>\n",
       "      <td>df[(df['S.01.01.01.01,R0580,C0010']=='REPORTED...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S.01.01_114</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.02.01.01.01,R0160,C0010\"} &gt; 0.05*({\"S.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.02.01.01.01,R0160,C0010']&gt;0.05*(df['...</td>\n",
       "      <td>df[(df['S.02.01.01.01,R0160,C0010']&gt;0.05*(df['...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S.01.02_102</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"S.01.02.01.01,R0050,C0010\"} = \"NETHERLANDS\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.02.01.01,R0050,C0010']=='NETHERLA...</td>\n",
       "      <td>df[~(df['S.01.02.01.01,R0050,C0010']=='NETHERL...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S.01.02_104</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"S.01.02.01.01,R0070,C0010\"} = \"DUTCH\" | {\"S....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[((df['S.01.02.01.01,R0070,C0010']=='DUTCH')...</td>\n",
       "      <td>df[~((df['S.01.02.01.01,R0070,C0010']=='DUTCH'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.01.02_110</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"S.01.02.01.01,R0100,C0010\"} = \"REGULAR REPOR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.02.01.01,R0100,C0010']=='REGULAR ...</td>\n",
       "      <td>df[~(df['S.01.02.01.01,R0100,C0010']=='REGULAR...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pattern_id  cluster  \\\n",
       "index                         \n",
       "0      S.01.01_111        0   \n",
       "1      S.01.01_114        0   \n",
       "2      S.01.02_102        0   \n",
       "3      S.01.02_104        0   \n",
       "4      S.01.02_110        0   \n",
       "\n",
       "                                             pattern_def  support  exceptions  \\\n",
       "index                                                                           \n",
       "0      IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...        0           0   \n",
       "1      IF {\"S.02.01.01.01,R0160,C0010\"} > 0.05*({\"S.0...        0           0   \n",
       "2          {\"S.01.02.01.01,R0050,C0010\"} = \"NETHERLANDS\"        0           0   \n",
       "3      {\"S.01.02.01.01,R0070,C0010\"} = \"DUTCH\" | {\"S....        0           0   \n",
       "4      {\"S.01.02.01.01,R0100,C0010\"} = \"REGULAR REPOR...        0           0   \n",
       "\n",
       "       confidence pattern status encodings  \\\n",
       "index                                        \n",
       "0               0            DNB        {}   \n",
       "1               0            DNB        {}   \n",
       "2               0            DNB        {}   \n",
       "3               0            DNB        {}   \n",
       "4               0            DNB        {}   \n",
       "\n",
       "                                               pandas co  \\\n",
       "index                                                      \n",
       "0      df[(df['S.01.01.01.01,R0580,C0010']=='REPORTED...   \n",
       "1      df[(df['S.02.01.01.01,R0160,C0010']>0.05*(df['...   \n",
       "2      df[(df['S.01.02.01.01,R0050,C0010']=='NETHERLA...   \n",
       "3      df[((df['S.01.02.01.01,R0070,C0010']=='DUTCH')...   \n",
       "4      df[(df['S.01.02.01.01,R0100,C0010']=='REGULAR ...   \n",
       "\n",
       "                                               pandas ex xbrl co xbrl ex  \\\n",
       "index                                                                      \n",
       "0      df[(df['S.01.01.01.01,R0580,C0010']=='REPORTED...                   \n",
       "1      df[(df['S.02.01.01.01,R0160,C0010']>0.05*(df['...                   \n",
       "2      df[~(df['S.01.02.01.01,R0050,C0010']=='NETHERL...                   \n",
       "3      df[~((df['S.01.02.01.01,R0070,C0010']=='DUTCH'...                   \n",
       "4      df[~(df['S.01.02.01.01,R0100,C0010']=='REGULAR...                   \n",
       "\n",
       "      Error message  \n",
       "index                \n",
       "0                    \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4                    "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patterns_closed_axis = df_patterns.copy()\n",
    "df_patterns_closed_axis = df_patterns_closed_axis[df_patterns_closed_axis['pandas ex'].apply(\n",
    "    lambda expr: not any(table in expr for table in tables_not_reported) \n",
    "    and not any(table in expr for table in tables_open_axis))]\n",
    "df_patterns_closed_axis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have:\n",
    "- the data for closed-axis tables in a dataframe;\n",
    "- the patterns for closed-axis tables in a dataframe.\n",
    "\n",
    "To evaluate the patterns we need to create a 'PatternMiner' (part of the data_patterns package), and run the analyze function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 212/212 [00:00<00:00, 502.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>result_type</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>support</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>confidence</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>P values</th>\n",
       "      <th>Q values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0LFF1WMNTWG5PTIYYI38</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>True</td>\n",
       "      <td>S.01.01_111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...</td>\n",
       "      <td>REPORTED</td>\n",
       "      <td>NOT REPORTED OTHER REASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>True</td>\n",
       "      <td>S.02.01_105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"S.02.01.01.01,R0040,C0010\"} &gt;= 0</td>\n",
       "      <td>8.70825e+08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>True</td>\n",
       "      <td>S.02.01_105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"S.02.01.01.01,R0780,C0010\"} &gt;= 0</td>\n",
       "      <td>1.17278e+08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>True</td>\n",
       "      <td>S.05.01_104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"S.05.01.01.01,R0550,C0010\"}&gt;=0</td>\n",
       "      <td>9.25496e+08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>True</td>\n",
       "      <td>S.05.01_104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"S.05.01.01.01,R0550,C0020\"}&gt;=0</td>\n",
       "      <td>6.83893e+07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 result_type   pattern_id  cluster  support  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31         True  S.01.01_111        0        1   \n",
       "                     2019-12-31         True  S.02.01_105        0        1   \n",
       "                     2019-12-31         True  S.02.01_105        0        1   \n",
       "                     2019-12-31         True  S.05.01_104        0        1   \n",
       "                     2019-12-31         True  S.05.01_104        0        1   \n",
       "\n",
       "                                 exceptions  confidence  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31           0         1.0   \n",
       "                     2019-12-31           0         1.0   \n",
       "                     2019-12-31           0         1.0   \n",
       "                     2019-12-31           0         1.0   \n",
       "                     2019-12-31           0         1.0   \n",
       "\n",
       "                                                                       pattern_def  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...   \n",
       "                     2019-12-31                {\"S.02.01.01.01,R0040,C0010\"} >= 0    \n",
       "                     2019-12-31                {\"S.02.01.01.01,R0780,C0010\"} >= 0    \n",
       "                     2019-12-31                   {\"S.05.01.01.01,R0550,C0010\"}>=0   \n",
       "                     2019-12-31                   {\"S.05.01.01.01,R0550,C0020\"}>=0   \n",
       "\n",
       "                                    P values                   Q values  \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31     REPORTED  NOT REPORTED OTHER REASON  \n",
       "                     2019-12-31  8.70825e+08                             \n",
       "                     2019-12-31  1.17278e+08                             \n",
       "                     2019-12-31  9.25496e+08                             \n",
       "                     2019-12-31  6.83893e+07                             "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miner = data_patterns.PatternMiner(df_patterns=df_patterns_closed_axis)\n",
    "df_results_closed_axis = miner.analyze(df_closed_axis)\n",
    "df_results_closed_axis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-axis tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First find the patterns defined for open-axis tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patterns_open_axis = df_patterns.copy()\n",
    "df_patterns_open_axis = df_patterns_open_axis[df_patterns_open_axis['pandas ex'].apply(\n",
    "    lambda expr: any(table in expr for table in tables_open_axis))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patterns involving multiple open-axis tables are not yet supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>support</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>confidence</th>\n",
       "      <th>pattern status</th>\n",
       "      <th>encodings</th>\n",
       "      <th>pandas co</th>\n",
       "      <th>pandas ex</th>\n",
       "      <th>xbrl co</th>\n",
       "      <th>xbrl ex</th>\n",
       "      <th>Error message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S.01.03_102</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; (df['S....</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; ~(df['S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S.01.03_104</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; (df['S....</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; ~(df['S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S.01.03_106</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; (df['S....</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; ~(df['S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S.01.03_108</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; (df['S....</td>\n",
       "      <td>df[(df['S.01.03.01.01,C0040']!=None) &amp; ~(df['S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S.01.03_111</td>\n",
       "      <td>0</td>\n",
       "      <td>IF {\"S.01.03.01.02,C0100\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DNB</td>\n",
       "      <td>{}</td>\n",
       "      <td>df[(df['S.01.03.01.02,C0100']!=None) &amp; (df['S....</td>\n",
       "      <td>df[(df['S.01.03.01.02,C0100']!=None) &amp; ~(df['S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pattern_id  cluster  \\\n",
       "index                         \n",
       "6      S.01.03_102        0   \n",
       "7      S.01.03_104        0   \n",
       "8      S.01.03_106        0   \n",
       "9      S.01.03_108        0   \n",
       "10     S.01.03_111        0   \n",
       "\n",
       "                                             pattern_def  support  exceptions  \\\n",
       "index                                                                           \n",
       "6      IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...        0           0   \n",
       "7      IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...        0           0   \n",
       "8      IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...        0           0   \n",
       "9      IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...        0           0   \n",
       "10     IF {\"S.01.03.01.02,C0100\"}!=None THEN {\"S.01.0...        0           0   \n",
       "\n",
       "       confidence pattern status encodings  \\\n",
       "index                                        \n",
       "6               0            DNB        {}   \n",
       "7               0            DNB        {}   \n",
       "8               0            DNB        {}   \n",
       "9               0            DNB        {}   \n",
       "10              0            DNB        {}   \n",
       "\n",
       "                                               pandas co  \\\n",
       "index                                                      \n",
       "6      df[(df['S.01.03.01.01,C0040']!=None) & (df['S....   \n",
       "7      df[(df['S.01.03.01.01,C0040']!=None) & (df['S....   \n",
       "8      df[(df['S.01.03.01.01,C0040']!=None) & (df['S....   \n",
       "9      df[(df['S.01.03.01.01,C0040']!=None) & (df['S....   \n",
       "10     df[(df['S.01.03.01.02,C0100']!=None) & (df['S....   \n",
       "\n",
       "                                               pandas ex xbrl co xbrl ex  \\\n",
       "index                                                                      \n",
       "6      df[(df['S.01.03.01.01,C0040']!=None) & ~(df['S...                   \n",
       "7      df[(df['S.01.03.01.01,C0040']!=None) & ~(df['S...                   \n",
       "8      df[(df['S.01.03.01.01,C0040']!=None) & ~(df['S...                   \n",
       "9      df[(df['S.01.03.01.01,C0040']!=None) & ~(df['S...                   \n",
       "10     df[(df['S.01.03.01.02,C0100']!=None) & ~(df['S...                   \n",
       "\n",
       "      Error message  \n",
       "index                \n",
       "6                    \n",
       "7                    \n",
       "8                    \n",
       "9                    \n",
       "10                   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patterns_open_axis = df_patterns_open_axis[df_patterns_open_axis['pandas ex'].apply(\n",
    "    lambda expr: len(set(re.findall('S.\\d\\d.\\d\\d.\\d\\d.\\d\\d',expr)))) == 1]\n",
    "df_patterns_open_axis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we loop through the open-axis tables en evaluate the corresponding patterns on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 666.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 666.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 666.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 666.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 642.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 599.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 636.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 599.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 615.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 571.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 636.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 555.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 666.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 624.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 499.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 428.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 499.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 428.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 400.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 499.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 428.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 499.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 624.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 461.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 428.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 499.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 666.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 499.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 499.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 470.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 533.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 499.87it/s]\n"
     ]
    }
   ],
   "source": [
    "output_open_axis = {}  # dictionary with input and results per table\n",
    "for table in tables_open_axis:  # loop through open-axis tables\n",
    "    if df_patterns_open_axis['pandas ex'].apply(lambda expr: table in expr).sum() > 0:  # check if there are patterns\n",
    "        info = {}\n",
    "        info['data'] = dict_open_axis[table]  # select data\n",
    "        info['patterns'] = df_patterns_open_axis[df_patterns_open_axis['pandas ex'].apply(\n",
    "            lambda expr: table in expr)]  # select patterns\n",
    "        miner = data_patterns.PatternMiner(df_patterns=info['patterns'])\n",
    "        info['results'] = miner.analyze(info['data'])  # evaluate patterns\n",
    "        output_open_axis[table] = info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results for the first table (if there are rules for tables with an open axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>result_type</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>support</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>confidence</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>P values</th>\n",
       "      <th>Q values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0LFF1WMNTWG5PTIYYI38</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2019-12-31</th>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>S.01.03_102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>RING FENCED FUNDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>S.01.03_104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT A FUND WITH OTHER FUNDS EMBEDDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>S.01.03_106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT MATERIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>S.01.03_108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>RFF NOT UNDER ARTICLE 304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   result_type   pattern_id  cluster  support  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31 1         True  S.01.03_102        0        1   \n",
       "                                1         True  S.01.03_104        0        1   \n",
       "                                1         True  S.01.03_106        0        1   \n",
       "                                1         True  S.01.03_108        0        1   \n",
       "\n",
       "                                   exceptions  confidence  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31 1           0         1.0   \n",
       "                                1           0         1.0   \n",
       "                                1           0         1.0   \n",
       "                                1           0         1.0   \n",
       "\n",
       "                                                                         pattern_def  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31 1  IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...   \n",
       "                                1  IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...   \n",
       "                                1  IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...   \n",
       "                                1  IF {\"S.01.03.01.01,C0040\"}!=None THEN {\"S.01.0...   \n",
       "\n",
       "                                  P values  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31 1        1   \n",
       "                                1        1   \n",
       "                                1        1   \n",
       "                                1        1   \n",
       "\n",
       "                                                               Q values  \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31 1                     RING FENCED FUNDS  \n",
       "                                1  NOT A FUND WITH OTHER FUNDS EMBEDDED  \n",
       "                                1                          NOT MATERIAL  \n",
       "                                1             RFF NOT UNDER ARTICLE 304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(output_open_axis.keys()) > 0:\n",
    "    display(output_open_axis[list(output_open_axis.keys())[0]]['results'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine results for closed- and open-axis tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output the results in a single file, we want to combine the results for closed-axis and open-axis tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform results for open-axis tables, so it can be appended to results for closed-axis tables\n",
    "# The 'extra' index columns are converted to data columns\n",
    "def transform_results_open_axis(df):\n",
    "    if df.index.nlevels > 2:\n",
    "        reset_index_levels = list(range(2, df.index.nlevels))\n",
    "        df = df.reset_index(level=reset_index_levels)\n",
    "        rename_columns={}\n",
    "        for x in reset_index_levels:\n",
    "            rename_columns['level_' + str(x)] = 'id_column_' + str(x - 1)\n",
    "        df.rename(columns=rename_columns, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results_closed_axis.copy()  # results for closed axis tables\n",
    "for table in list(output_open_axis.keys()):  # for all open axis tables with rules -> append and sort results\n",
    "    df_results = transform_results_open_axis(output_open_axis[table]['results']).append(df_results, sort=False).sort_values(by=['pattern_id']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column order so the dataframe starts with the identifying columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id_column_1</th>\n",
       "      <th>id_column_2</th>\n",
       "      <th>id_column_3</th>\n",
       "      <th>id_column_4</th>\n",
       "      <th>id_column_5</th>\n",
       "      <th>id_column_6</th>\n",
       "      <th>id_column_7</th>\n",
       "      <th>id_column_8</th>\n",
       "      <th>result_type</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>support</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>confidence</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>P values</th>\n",
       "      <th>Q values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0LFF1WMNTWG5PTIYYI38</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>S.01.01_111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...</td>\n",
       "      <td>REPORTED</td>\n",
       "      <td>NOT REPORTED OTHER REASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>S.01.01_114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IF {\"S.02.01.01.01,R0160,C0010\"} &gt; 0.05*({\"S.0...</td>\n",
       "      <td>[660329585.57, 339431184.66, 563296271.46]</td>\n",
       "      <td>NOT DUE IN ACCORDANCE WITH INSTRUCTIONS OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>S.01.02_102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"S.01.02.01.01,R0050,C0010\"} = \"NETHERLANDS\"</td>\n",
       "      <td>SUDAN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>S.01.02_104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"S.01.02.01.01,R0070,C0010\"} = \"DUTCH\" | {\"S....</td>\n",
       "      <td>TATAR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>S.01.02_110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"S.01.02.01.01,R0100,C0010\"} = \"REGULAR REPOR...</td>\n",
       "      <td>EMPTY SUBMISSION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id_column_1 id_column_2 id_column_3  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "\n",
       "                                id_column_4 id_column_5 id_column_6  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "                     2019-12-31         NaN         NaN         NaN   \n",
       "\n",
       "                                id_column_7 id_column_8  result_type  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31         NaN         NaN         True   \n",
       "                     2019-12-31         NaN         NaN        False   \n",
       "                     2019-12-31         NaN         NaN        False   \n",
       "                     2019-12-31         NaN         NaN        False   \n",
       "                     2019-12-31         NaN         NaN        False   \n",
       "\n",
       "                                  pattern_id  cluster  support  exceptions  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  S.01.01_111        0        1           0   \n",
       "                     2019-12-31  S.01.01_114        0        0           1   \n",
       "                     2019-12-31  S.01.02_102        0        0           1   \n",
       "                     2019-12-31  S.01.02_104        0        0           1   \n",
       "                     2019-12-31  S.01.02_110        0        0           1   \n",
       "\n",
       "                                 confidence  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31         1.0   \n",
       "                     2019-12-31         0.0   \n",
       "                     2019-12-31         0.0   \n",
       "                     2019-12-31         0.0   \n",
       "                     2019-12-31         0.0   \n",
       "\n",
       "                                                                       pattern_def  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31  IF {\"S.01.01.01.01,R0580,C0010\"} = \"REPORTED\" ...   \n",
       "                     2019-12-31  IF {\"S.02.01.01.01,R0160,C0010\"} > 0.05*({\"S.0...   \n",
       "                     2019-12-31      {\"S.01.02.01.01,R0050,C0010\"} = \"NETHERLANDS\"   \n",
       "                     2019-12-31  {\"S.01.02.01.01,R0070,C0010\"} = \"DUTCH\" | {\"S....   \n",
       "                     2019-12-31  {\"S.01.02.01.01,R0100,C0010\"} = \"REGULAR REPOR...   \n",
       "\n",
       "                                                                   P values  \\\n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31                                    REPORTED   \n",
       "                     2019-12-31  [660329585.57, 339431184.66, 563296271.46]   \n",
       "                     2019-12-31                                       SUDAN   \n",
       "                     2019-12-31                                       TATAR   \n",
       "                     2019-12-31                            EMPTY SUBMISSION   \n",
       "\n",
       "                                                                          Q values  \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31                          NOT REPORTED OTHER REASON  \n",
       "                     2019-12-31  NOT DUE IN ACCORDANCE WITH INSTRUCTIONS OF THE...  \n",
       "                     2019-12-31                                                     \n",
       "                     2019-12-31                                                     \n",
       "                     2019-12-31                                                     "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_col_order = []\n",
    "for i in range(1, len([col for col in list(df_results.columns) if col[:10] == 'id_column_']) + 1):\n",
    "    list_col_order.append('id_column_' + str(i))\n",
    "list_col_order.extend(col for col in list(df_results.columns) if col not in list_col_order)\n",
    "df_results = df_results[list_col_order]\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe df_results contains all output of the evaluation of the validation rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save all results use df_results\n",
    "# To save all exceptions use df_results['result_type']==False \n",
    "# To save all confirmations use df_results['result_type']==True\n",
    "\n",
    "# Here we save only the exceptions to the validation rules\n",
    "df_results[df_results['result_type']==False].to_excel(join(RESULTS_PATH, \"results.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of an error in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: df_closed_axis[~(df_closed_axis['S.01.02.01.01,R0100,C0010']=='REGULAR REPORTING')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>S.01.02.01.01,R0100,C0010</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0LFF1WMNTWG5PTIYYI38</th>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>EMPTY SUBMISSION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                S.01.02.01.01,R0100,C0010\n",
       "entity               period                              \n",
       "0LFF1WMNTWG5PTIYYI38 2019-12-31          EMPTY SUBMISSION"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the pandas code from the first pattern and evaluate it\n",
    "s = df_patterns.loc[4, 'pandas ex'].replace('df', 'df_closed_axis')\n",
    "print('Pattern:', s)\n",
    "display(eval(s)[re.findall('S.\\d\\d.\\d\\d.\\d\\d.\\d\\d,R\\d\\d\\d\\d,C\\d\\d\\d\\d',s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
