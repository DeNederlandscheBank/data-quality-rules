{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial describes how to evaluate rules that are applicable to two consecutive periods (year and quarter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arelle import ModelManager, Cntlr, ModelFormulaObject, ModelXbrl, ViewFileFormulae, XbrlConst, ViewFileRenderedGrid\n",
    "from arelle import RenderingEvaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "import pickle\n",
    "import re\n",
    "from src import Evaluator\n",
    "import logging\n",
    "import data_patterns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECIMALS = 0\n",
    "RULES_PATH = join('..', 'ftk-rules')\n",
    "INSTANCES_DATA_PATH = join('..','data','instances')\n",
    "DATAPOINTS_PATH = join('..', 'data', 'datapoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with importing the (t-1)-t rules that are applicable to two consecutive periods. We import a set of rules used to evaluate year data and a set of rules for quarter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTK_betweenperiods_JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_JS = pd.read_excel(join(RULES_PATH,'FTK_betweenperiods_JS.xlsx'), engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTK_betweenperiods_BEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_BEL = pd.read_excel(join(RULES_PATH,'FTK_betweenperiods_BEL.xlsx'), engine='openpyxl')\n",
    "dfr_BEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import the reporting data. We import the data of two consecutive periods. In the tutorial 'Convert XBRL-instances to CSV, HTML and pickles' the XBRL-instances are converted to pickle files per template. The pickle files are written to the data/instances folder. The rules are applicable to all tables with closed axis. We import these pickle files. When comparing two periods it can be the case that two different taxonomies are applicable. The right taxonomy has to be selected in the tutorial 'Convert XBRL-instances to CSV, HTML and pickles' to convert the XBRL-instance properly. \n",
    "\n",
    "The list _instances_JS_ contains the names of the folders with the converted XBRL-instance for yearly data. The list _instances_BEL_ contains the names of the folders with the converted XBRL-instance for two consecutive quarters. Finally, we also have to define the category of the insurer. The rules are set-up for each type of insurer separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_JS = []\n",
    "instances_BEL = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTK_betweenperiods_JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(join(DATAPOINTS_PATH, 'JS.pkl'), 'rb') as handle:\n",
    "#     JS = pickle.load(handle)\n",
    "# dft = pd.DataFrame()\n",
    "# for instance in instances_JS:\n",
    "#     df_closed_axis = pd.DataFrame()\n",
    "#     tables_closed_axis = []  # for listing all input tables with closed axis\n",
    "#     tables = [table for table in JS \n",
    "#         if isfile(join(INSTANCES_DATA_PATH,instance,table + '.pickle'))]  # JS tables found in the specified instance path\n",
    "#     for table in [table for table in tables]:  #tables:\n",
    "#         if isfile(join(INSTANCES_DATA_PATH,instance, table + '.pickle')):\n",
    "#             df = pd.read_pickle(join(INSTANCES_DATA_PATH,instance, table + '.pickle'))  # read dataframe\n",
    "#         else:\n",
    "#             continue   \n",
    "#         if df.index.nlevels > 2:  # if more than 2 indexes (entity, period), then the table has an open axis\n",
    "#             continue\n",
    "#         else:  # closed axis\n",
    "#             tables_closed_axis.append(table)  # add to relevant list\n",
    "#             # Add table to dataframe with all data from closed axis tables\n",
    "#             if len(df_closed_axis) == 0:  # no data yet --> copy dataframe\n",
    "#                 df_closed_axis = df.copy()\n",
    "#             else:  # join to existing dataframe\n",
    "#                 df_closed_axis = df_closed_axis.join(df)\n",
    "#     if len(dft) == 0:  # no data yet \n",
    "#         dft = df_closed_axis\n",
    "#     else:  # join to existing dataframe\n",
    "#         dft=dft.append(df_closed_axis)\n",
    "# dft=dft.reset_index()\n",
    "# numerical_columns = ['entity','period'] + [dft.columns[c] for c in range(len(dft.columns))\n",
    "#                          if ((dft.dtypes[c] == 'float64') or (dft.dtypes[c] == 'int64'))]\n",
    "# df_JS = dft[numerical_columns]\n",
    "# df_JS['period']=df_JS['period'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d')) #convert to datetime\n",
    "# df_JS.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we work with dummy data in order to show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('..','tests','data','demo','FTK_JS.pkl'), 'rb') as handle:\n",
    "    df_JS = pickle.load(handle)\n",
    "df_JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S2_betweenperiods_QRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(join(DATAPOINTS_PATH, 'BEL.pkl'), 'rb') as handle:\n",
    "#     BEL = pickle.load(handle)\n",
    "# dft = pd.DataFrame()\n",
    "# for instance in instances_BEL:\n",
    "#     df_closed_axis = pd.DataFrame()\n",
    "#     tables_closed_axis = []  # for listing all input tables with closed axis\n",
    "#     tables = [table for table in BEL \n",
    "#         if isfile(join(INSTANCES_DATA_PATH,instance,table + '.pickle'))]  # BEL tables found in the specified instance path\n",
    "#     for table in [table for table in tables]:  #tables:\n",
    "#         if isfile(join(INSTANCES_DATA_PATH,instance, table + '.pickle')):\n",
    "#             df = pd.read_pickle(join(INSTANCES_DATA_PATH,instance, table + '.pickle'))  # read dataframe\n",
    "#         else:\n",
    "#             continue   \n",
    "#         if df.index.nlevels > 2:  # if more than 2 indexes (entity, period), then the table has an open axis\n",
    "#             continue\n",
    "#         else:  # closed axis\n",
    "#             tables_closed_axis.append(table)  # add to relevant list\n",
    "#             # Add table to dataframe with all data from closed axis tables\n",
    "#             if len(df_closed_axis) == 0:  # no data yet --> copy dataframe\n",
    "#                 df_closed_axis = df.copy()\n",
    "#             else:  # join to existing dataframe\n",
    "#                 df_closed_axis = df_closed_axis.join(df)\n",
    "#     if len(dft) == 0:  # no data yet \n",
    "#         dft = df_closed_axis\n",
    "#     else:  # join to existing dataframe\n",
    "#         dft=dft.append(df_closed_axis)\n",
    "# dft=dft.reset_index()\n",
    "# numerical_columns = ['entity','period'] + [dft.columns[c] for c in range(len(dft.columns))\n",
    "#                          if ((dft.dtypes[c] == 'float64') or (dft.dtypes[c] == 'int64'))]\n",
    "# df_BEL = dft[numerical_columns]\n",
    "# df_BEL['period']=df_BEL['period'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d')) #convert to datetime\n",
    "# df_BEL.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we work with dummy data in order to show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('..','tests','data','demo','FTK_BEL.pkl'), 'rb') as handle:\n",
    "    df_BEL = pickle.load(handle)\n",
    "df_BEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate FTK_betweenperiods_JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analyze\n",
    "miner = data_patterns.PatternMiner(df_patterns=dfr_JS)\n",
    "miner.df_data = df_JS\n",
    "miner.convert_to_time(['entity'], 'period')\n",
    "miner.df_data = miner.df_data.reset_index()\n",
    "\n",
    "results = miner.analyze()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTK_betweenperiods_BEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analyze\n",
    "miner = data_patterns.PatternMiner(df_patterns=dfr_BEL)\n",
    "miner.df_data = df_BEL\n",
    "miner.convert_to_time(['entity'], 'period', set_year=False)\n",
    "miner.df_data = miner.df_data.reset_index()\n",
    "\n",
    "results = miner.analyze()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
