{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import ast\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES_PATH = '..//solvency2-rules//'\n",
    "FILENAME_RULES = '2020-01-22 Set aanvullende controleregels Solvency II_tcm46-387021.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct test Solvency 2 instance (put here your own data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '..\\\\results\\\\'\n",
    "DATA_PATH = '..\\\\data\\\\'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df.index.name = \"index\"\n",
    "files = [f for f in os.listdir(RESULTS_PATH) if os.path.isfile(os.path.join(RESULTS_PATH, f)) if f[-6:]=='pickle']\n",
    "for file in files:\n",
    "    new_df = pd.read_pickle(os.path.join(RESULTS_PATH, file))\n",
    "    new_df.columns = [col.upper() for col in new_df.columns]\n",
    "    if list(new_df.index) == [0]: # without z-axis for now\n",
    "        for col in new_df.columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = new_df[col]\n",
    "    else:\n",
    "        for col in new_df.columns:\n",
    "            if col not in df.columns:\n",
    "                # we only pick the first line in the z-axis column\n",
    "                df.loc[0, col] = new_df.iloc[0, new_df.columns.get_loc(col)]\n",
    "        df.loc[0, new_df.index.name] = new_df.index[0]\n",
    "df = df.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simple taxonomy based on instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxo = pd.DataFrame(columns = ['datapoint', 'template', 'row', 'column', 'dtype'])\n",
    "for idx, col in enumerate(df.columns):\n",
    "    df_taxo.loc[idx, \"datapoint\"] = col.upper()\n",
    "    df_taxo.loc[idx, \"template\"] = col[0:13].upper()\n",
    "    df_taxo.loc[idx, \"row\"] = col[14:19].upper()\n",
    "    df_taxo.loc[idx, \"column\"] = col[20:25].upper()\n",
    "    df_taxo.loc[idx, \"dtype\"] = df.dtypes[idx]\n",
    "df_taxo.head(5)\n",
    "\n",
    "# for now we only use the list of templates in the instance\n",
    "instance_templates = list(df_taxo.loc[:, 'template'].unique())\n",
    "del df_taxo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DNBs Additional Validation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = pd.read_excel(os.path.join(RULES_PATH, FILENAME_RULES), header = 1)\n",
    "df_rules = df_rules.set_index('ControleRegelCode')\n",
    "df_rules = df_rules.drop('S.28.01_129', axis = 0) # double line, should be removed\n",
    "df_rules = df_rules.drop('S.01.03_110', axis = 0) # double line, should be removed\n",
    "df_rules.fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_and_or(s):\n",
    "    \"\"\"Replace and by & and or by |, but not within strings\"\"\"\n",
    "    if re.search(r\"(.*?)\\'(.*?)\\'(.*)\", s) is None: # input text does not contain strings\n",
    "        s = s.replace(\"OR\", \"|\")\n",
    "        s = s.replace(\"AND\", \"&\")\n",
    "    for item in re.findall(r\"(.*?)\\'(.*?)\\'(.*)\", s):\n",
    "        s = s.replace(item[0], item[0].replace(\"OR\", \"|\"))\n",
    "        s = s.replace(item[0], item[0].replace(\"AND\", \"&\"))\n",
    "        s = s.replace(item[2], replace_and_or(item[2]))\n",
    "    return s\n",
    "\n",
    "def preprocess(s):\n",
    "    \"\"\"Transform EVA2 code to Python Pandas code\"\"\"\n",
    "    res = s\n",
    "    res = res.replace(\"=\" , \"==\")\n",
    "    res = res.replace(\">==\" , \">=\")\n",
    "    res = res.replace(\"<==\" , \"<=\")\n",
    "    res = res.replace(\"<>\", \"!=\")\n",
    "    res = res.replace(\"< >\", \"!=\") # the space between < and > should be deleted in EVA2\n",
    "    res = res.replace('\"', \"'\")\n",
    "    res = replace_and_or(res)\n",
    "    res = res.replace(\" )\", \")\")\n",
    "    res = res.replace(';', \",\") # this should be corrected in EVA2\n",
    "    return res\n",
    "\n",
    "def datapoints2pandas(s):\n",
    "    \"\"\"Transform EVA2 datapoints to Python Pandas datapoints\"\"\"\n",
    "    res = s\n",
    "    datapoints = []\n",
    "    for item in re.findall(r'{(.*?)}', res):\n",
    "        res = res.replace(\"{\"+item+\"}\", \"df['\"+item.upper()+\"']\")\n",
    "        datapoints.append(item.upper())\n",
    "    return res, datapoints\n",
    "\n",
    "def add_brackets(s):\n",
    "    \"\"\"Add brackets around expressions with & and | (this is not consistent in EVA2)\n",
    "    TODO: should not apply is AND or OR is in string text\n",
    "    \"\"\"\n",
    "    item = re.search(r'(.*)([&|\\|])(.*)', s) # & and | takes priority over other functions like ==\n",
    "    if item is not None:\n",
    "        return '('+ add_brackets(item.group(1)) + ') ' + item.group(2).strip() + ' (' + add_brackets(item.group(3)) + ')'\n",
    "    else:\n",
    "        item = re.search(r'(.*)([>|<|!=|<=|>=|==])(.*)', s)\n",
    "        if item is not None:\n",
    "            return add_brackets(item.group(1)) + item.group(2).strip() + add_brackets(item.group(3))\n",
    "        else:\n",
    "            return s.strip()\n",
    "    \n",
    "def expression2pandas(g):\n",
    "    \"\"\"Transform EVA2 conditional expression to Python Pandas code\"\"\"\n",
    "    item = re.search(r'IF(.*)THEN(.*)', g)\n",
    "    if item is not None:\n",
    "        co_str = 'df[('+add_brackets(item.group(1))+') & ('+add_brackets(item.group(2))+\")]\"\n",
    "        ex_str = 'df[('+add_brackets(item.group(1))+') & ~('+add_brackets(item.group(2))+\")]\"\n",
    "    else:\n",
    "        co_str = 'df[('+add_brackets(g)+')]'\n",
    "        ex_str = 'df[~('+add_brackets(g)+')]'\n",
    "    return co_str, ex_str\n",
    "\n",
    "def evaluate_strings(df_data, co_str, ex_str):\n",
    "    \"\"\"Evaluate Python Pandas string for confirmation and exceptions\"\"\"\n",
    "    try:\n",
    "        co = len(eval(co_str, {'df': df_data, 'MAX': np.maximum, 'MIN': np.minimum, 'SUM': np.sum}))\n",
    "        ex = len(eval(ex_str, {'df': df_data, 'MAX': np.maximum, 'MIN': np.minimum, 'SUM': np.sum}))\n",
    "        return \"Correctly parsed (#co=\" + str(co)+\", #ex=\"+str(ex)+\")\"\n",
    "    except TypeError as e:\n",
    "        return \"Parse error: \" + co_str + \": \" + str(e)\n",
    "    except:\n",
    "        return \"Parse error: \" + co_str + \": UNKNOWN ERROR\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2pandas(df_data, rule_original):\n",
    "    g = preprocess(rule_original)\n",
    "    g, datapoints = datapoints2pandas(g)\n",
    "    co_str, ex_str = expression2pandas(g)\n",
    "    return co_str, ex_str, datapoints\n",
    "\n",
    "def transform_rules(df_data, df_rules):\n",
    "    for row in df_rules.index:\n",
    "        rule_original = df_rules.loc[row, 'Formule']\n",
    "        if not isinstance(rule_original, str):\n",
    "            print(\"Rule \" + row + \": \" + \"duplicate rule. \")\n",
    "            rule_original = rule_original.values[0]\n",
    "        else:\n",
    "            co_str, ex_str, datapoints = transform2pandas(df_data, rule_original)\n",
    "            df_rules.loc[row, 'pandas co'] = co_str\n",
    "            df_rules.loc[row, 'pandas ex'] = ex_str\n",
    "            df_rules.at[row, 'datapoints'] = ''\n",
    "            df_rules.at[row, 'datapoints'] = df_rules['datapoints'].astype('object')\n",
    "            df_rules.at[row, 'datapoints'] = datapoints\n",
    "            df_rules.at[row, 'templates'] = ''\n",
    "            df_rules.at[row, 'templates'] = df_rules['templates'].astype('object')\n",
    "            df_rules.at[row, 'templates'] = [datapoint[0:13].upper() for datapoint in datapoints]\n",
    "\n",
    "def evaluate_rule(df, co_str, ex_str, datapoints, substitutions, expansion_dict):\n",
    "    if datapoints == []:\n",
    "        for item in substitutions.keys():\n",
    "            co_str = co_str.replace(item, substitutions[item])\n",
    "            ex_str = ex_str.replace(item, substitutions[item])\n",
    "        print(evaluate_strings(df, co_str, ex_str))\n",
    "    else:\n",
    "        datapoint = datapoints.pop()\n",
    "        if datapoint in expansion_dict.keys():\n",
    "            for d in expansion_dict[datapoint]:\n",
    "                substitutions[datapoint] = d\n",
    "                evaluate_rule(df, co_str, ex_str, datapoints, substitutions, expansion_dict)\n",
    "        else:\n",
    "            evaluate_rule(df, co_str, ex_str, datapoints, substitutions, expansion_dict)\n",
    "\n",
    "def evaluate_rules(df, df_rules):\n",
    "    for idx in range(len(df_rules.index)):\n",
    "        row = df_rules.index[idx]\n",
    "        print(str(idx) + \": \", end='')\n",
    "        rule_original = df_rules.loc[row, 'Formule']\n",
    "        datapoints = df_rules.loc[row, 'datapoints']\n",
    "        templates = df_rules.loc[row, 'templates']\n",
    "        # are the templates in the rule in the instance?\n",
    "        templates_not_found = []\n",
    "        for template in templates:\n",
    "            if template not in instance_templates:\n",
    "                templates_not_found.append(template)\n",
    "                \n",
    "        if templates_not_found == []:\n",
    "            datapoints_not_found = []\n",
    "            expansion_dict = {}\n",
    "            # are the datapoints in the rule in the instance?\n",
    "            for datapoint in datapoints:\n",
    "                if datapoint not in df.columns:\n",
    "                    all_datapoints_found = False\n",
    "                    new_list = []\n",
    "                    if datapoint[14]==\"C\":\n",
    "                        for col in df.columns:\n",
    "                            reg = re.search(datapoint[0:14] + \"R....,\" + datapoint[14:], col)\n",
    "                            if reg:\n",
    "                                new_list.append(reg.group(0))\n",
    "                    if datapoint[14]==\"R\":\n",
    "                        for col in df.columns:\n",
    "                            reg = re.search(datapoint + \",C....\", col)\n",
    "                            if reg:\n",
    "                                new_list.append(reg.group(0))\n",
    "                    if new_list != []:\n",
    "                        expansion_dict[datapoint] = new_list\n",
    "                    else:\n",
    "                        datapoints_not_found.append(datapoint)\n",
    "            if datapoints_not_found == []:\n",
    "                co_str = df_rules.loc[row, 'pandas co']\n",
    "                ex_str = df_rules.loc[row, 'pandas ex']\n",
    "                evaluate_rule(df, co_str, ex_str, datapoints, {}, expansion_dict)\n",
    "            else:\n",
    "                print(\"Datapoints not found: \" +str(datapoints_not_found))\n",
    "        else:\n",
    "            print(\"Not all templates in instance: \" + str(templates_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_rules(df, df_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rules(df, df_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
