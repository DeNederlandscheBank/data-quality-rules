{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert DNBs Additional Validation Rules to Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNBs additional validation rules are available in the 'solvency2-rules' subfolder of the repository.  \n",
    "The formulas in this file use a specific syntax, this notebook converts this syntax to a syntax that can be interpreted by Python.  \n",
    "The resulting formulas are called 'patterns'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # dataframes\n",
    "from os.path import join # some os dependent functionality\n",
    "import re # regex\n",
    "from src import adjust_syntax  # adjust syntax of additional Solvency 2 validation rules\n",
    "from src import Evaluator  # conversion from 'rules' to pandas expressions for the data-patterns packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location and name of the file with the additional rules:\n",
    "RULES_PATH = join('..', 'data', 'downloaded files')\n",
    "FILENAME_RULES = '2022_02_23_set_aanvullende_controleregels_solvency2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location and names of files with all possible datapoints for QRS and ARS\n",
    "DATAPOINTS_PATH = join('..', 'data', 'datapoints')\n",
    "FILENAME_DATAPOINTS_QRS = 'QRS.csv'\n",
    "FILENAME_DATAPOINTS_ARS = 'ARS.csv'\n",
    "FILENAME_DATAPOINTS_QRG = 'QRG.csv'\n",
    "FILENAME_DATAPOINTS_ARG = 'ARG.csv'\n",
    "FILENAME_DATAPOINTS_QFS = 'QFS.csv'\n",
    "FILENAME_DATAPOINTS_QFG = 'QFG.csv'\n",
    "FILENAME_DATAPOINTS_VER = 'VER.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters:\n",
    "PARAMETERS = {'decimal': 0}\n",
    "# currently only 'decimal' is available which specifies tolerance during evaluation of patterns.\n",
    "# decimal: 0 means tolerance = abs(1.5e-0) (= 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We log to rules.log in the data/instances path\n",
    "# logging.basicConfig(filename = join(INSTANCES_DATA_PATH, 'rules.log'),level = logging.INFO, \n",
    "#                     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file with all possible datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simplified taxonomy with all possible datapoints, located in the data/datapoints directory.  \n",
    "The evaluator uses this taxonomy to generate the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files to dataframe:\n",
    "df_datapoints_qrs = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_QRS), sep=\";\").fillna(\"\")\n",
    "df_datapoints_ars = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_ARS), sep=\";\").fillna(\"\")\n",
    "df_datapoints_qrg = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_QRG), sep=\";\").fillna(\"\")\n",
    "df_datapoints_arg = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_ARG), sep=\";\").fillna(\"\")\n",
    "df_datapoints_qfs = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_QFS), sep=\";\").fillna(\"\")\n",
    "df_datapoints_qfg = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_QFG), sep=\";\").fillna(\"\")\n",
    "df_datapoints_ver = pd.read_csv(join(DATAPOINTS_PATH, FILENAME_DATAPOINTS_VER), sep=\";\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into a single dataframe with all datapoints\n",
    "df_datapoints = pd.concat([df_datapoints_qrs, df_datapoints_ars, df_datapoints_qrg, df_datapoints_arg,\n",
    "                           df_datapoints_qfs, df_datapoints_qfg, df_datapoints_ver\n",
    "                          ], ignore_index = True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datapoints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DNBs Additional Validation Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNBs additional validation rules are currently published as an Excel file on the DNB statistics website. We included the Excel file here in the project.\n",
    "\n",
    "Here we read the Excel and perform some data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = pd.read_excel(join(RULES_PATH, FILENAME_RULES), header = 1, engine='openpyxl')\n",
    "df_rules.drop_duplicates(inplace=True) #remove double lines\n",
    "df_rules.fillna(\"\", inplace = True)\n",
    "df_rules = df_rules.set_index('ControleRegelCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust syntax of additional Solvency 2 validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = adjust_syntax(df_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Excel file contains rules for different report-types. In the next step we filter out the rules for QRS, ARS, QRG and ARG respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules_qrs = df_rules.copy()[(df_rules['Standaard'] == 'SOLVENCY') | (df_rules['Standaard'] == 'QRS')]\n",
    "df_rules_ars = df_rules.copy()[(df_rules['Standaard'] == 'SOLVENCY') | (df_rules['Standaard'] == 'ARS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules_qrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules_ars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the rules to patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluator is a piece of Python code, which takes the Additional Validation Rules as input, and transforms it to expressions that can be interpreted by the data_patterns package (patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_qrs = Evaluator(df_rules_qrs, df_datapoints, PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_qrs.df_patterns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_ars = Evaluator(df_rules_ars, df_datapoints, PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_ars.df_patterns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export patterns to rules folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_qrs.df_patterns.to_excel(join('..', 'solvency2-rules', \"qrs_patterns_additional_rules.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_ars.df_patterns.to_excel(join('..', 'solvency2-rules', \"ars_patterns_additional_rules.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqr_eva2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "21b176772a6c742f14e767e147c714614e0065ff528d0fa105ef1e84b18d9160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
